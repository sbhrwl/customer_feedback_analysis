stages:
  save_raw_data:
    cmd: python src/save_raw_data/save_raw_data.py
    deps:
    - src/get_parameters/get_parameters.py
    - src/save_raw_data/save_raw_data.py
    - dataset/source/dataset_source.csv
    outs:
    - dataset/raw/dataset_raw.csv

  clean_data:
    cmd: python src/preprocessing/clean_data/clean_data.py
    deps:
    - src/get_parameters/get_parameters.py
    - src/preprocessing/clean_data/clean_data.py
    - dataset/raw/dataset_raw.csv
    outs:
    - dataset/processed/basic_cleaning/dataset_no_punctuations.csv
    - dataset/processed/basic_cleaning/dataset_tokenised.csv
    - dataset/processed/basic_cleaning/dataset_no_stop_words.csv

  perform_stemming_lemmatization:
    cmd: python src/preprocessing/perform_stemming_lemmatization/perform_stemming_lemmatization.py
    deps:
    - src/get_parameters/get_parameters.py
    - src/preprocessing/perform_stemming_lemmatization/perform_stemming_lemmatization.py
    - dataset/raw/dataset_raw.csv
    outs:
    - dataset/processed/stemmed_lemmatised/dataset_stemmed.csv
    - dataset/processed/stemmed_lemmatised/dataset_lemmatised.csv

  text_vectorization:
    cmd: python src/preprocessing/text_vectorization/text_vectorization.py
    deps:
    - src/get_parameters/get_parameters.py
    - src/preprocessing/text_vectorization/text_vectorization.py
    - dataset/raw/dataset_raw.csv
    outs:
    - dataset/processed/vectorized/dataset_count_vectorized.csv
    - dataset/processed/vectorized/dataset_ngram_count_vectorized.csv
    - dataset/processed/vectorized/dataset_tfidf_vectorised.csv

  create_features:
    cmd: python src/preprocessing/create_features/create_features.py
    deps:
      - src/get_parameters/get_parameters.py
      - src/preprocessing/create_features/create_features.py
      - dataset/raw/dataset_raw.csv
    outs:
      - dataset/processed/new_features_added/dataset_with_new_features.csv

  feature_analysis:
    cmd: python src/eda/feature_analysis.py
    deps:
      - src/get_parameters/get_parameters.py
      - src/eda/feature_analysis.py
      - dataset/processed/new_features_added/dataset_with_new_features.csv
    outs:
      - artifacts/eda-artifacts/histograms/message_length_analysis.png
      - artifacts/eda-artifacts/histograms/message_length_logarithmic_analysis.png
      - artifacts/eda-artifacts/histograms/punctuation_percent_analysis.png

  create_word_cloud:
    cmd: python src/eda/create_word_cloud.py
    deps:
      - src/get_parameters/get_parameters.py
      - src/eda/create_word_cloud.py
      - dataset/processed/new_features_added/dataset_with_new_features.csv
    outs:
      - artifacts/eda-artifacts/word_cloud/word_cloud_good.png

#  train_and_evaluate:
#    cmd: python src/train_and_evaluate/train_and_evaluate.py
#    deps:
#      - src/get_parameters/get_parameters.py
#      - src/train_and_evaluate/train_and_evaluate.py
#      - dataset/raw/dataset_raw.csv
#    outs:
#    - artifacts/model-artifacts/confusion_matrix_analysis.png
#
#  pycaret_automl:
#    cmd: python src/pycaret_auto_ml/pycaret_auto_ml.py
#    deps:
#      - src/get_parameters/get_parameters.py
#      - src/pycaret_auto_ml/pycaret_auto_ml.py
#      - dataset/raw/dataset_raw.csv
#    outs:
#      - artifacts/automl-artifacts/pycaret_artifacts/pycaret_regressor-output-file.txt
#      - artifacts/automl-artifacts/pycaret_artifacts/pycaret_best_model-output-file.txt