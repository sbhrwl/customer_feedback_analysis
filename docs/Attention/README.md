# Attention
- [Paper](https://arxiv.org/pdf/1706.03762.pdf)
- [NMT with Attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- Self Attention
